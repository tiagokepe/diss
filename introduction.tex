\chapter{Introduction} % (fold)
\label{cha:introduction}

\section{Motivation}

MapReduce~\cite{Dean:2004} became the industry de facto standard for parallel processing. Attractive features such as scalability and reliability motivate many large companies such as Facebook, Google, Yahoo and research institutes to adopt this new programming paradigm. 
These organizations rely on Hadoop~\cite{White:2009}, an open-source implementation of MapReduce, to process their information.
Besides Hadoop, several other implementations are available: Greenplum MapReduce~\cite{Greenplum:2008}, Aster Data~\cite{Aster:2011}, Nokia Disco~\cite{Mundkur:2011},  Microsoft Dryad~\cite{Isard:2007}, among others.

MapReduce has a simplified programming model, where data processing algorithms are implemented as instances of two higher-order functions: Map and Reduce. All complex issues related to distributed processing, such as scalability, data distribution and reconciliation, concurrence, fault tolerance, etc., are managed by the framework.
The main complexity that is left to the developer of a MapReduce-based application (also called a job) lies in the design decisions made to split the application specific algorithm into two higher-order functions. Even if some decisions may result in a functionally correct application, bad design choices might also lead to poor resource usage.

A good configuration can improve the job performance and one relevant aspect is
that the MapReduce jobs work with large amounts of data, such fact is the
main barrier to find a good configuration. Therefore a data sample is
essencial, but generate a representative and relevant data sampling is hard
and a bad sampling may not represent several aspects related to the computation
in large-scale: efficient resource usage, correct merge of data, intermediate
data, etc.


Hence is very important to adjust the configuration knobs for each job and this
configutarion must be specific for own job. However, according with the cluster
variation, eg. to add or to remove machines, the data insertion or remotion,
may be need to adjust again the job configuration.

Find a good configuration is not so easy and may spend much time. So
one way to automate the job configuration is very useful for users.

\section{Contribution}

We present an original approach to automate Hadoop job configuration, our
implementation is basead in an evolutionary algorithm \cite{baudry} and in
order to use this algorithm we develop a method to obtain data sample on
hadoop cluster. To develop this method we needed to consider a lot of
aspects related the paradigm MapReduce, key-value model and others hadoop
particularities. Our framework has an user interface which have been implementing
with domain specific language ({\bf DSL}), it's a front end for the users and facilitates the
use of the our framework, after ran it the user can obtain the job configuration
resultant, so the users have a tool end-to-end.

The work presented here contributes to the establishment a framework to automate
Hadoop job configuration, through the following proposals:
\begin{itemize}
	\item a interface for users basead on domain specific language;
	\item an algorithm to automate a good choice of jobs configuration;
	\item a method for sampling data on Hadoop clusters.
\end{itemize}

\section{Outline}

\begin{itemize}
	\item Chapter \ref{cha:background} introduces the fundamental concepts of the MapReduce framework.
	\item Chapter \ref{cha:dsn} introduces the concepts of the domain specific language.
	\item Chapter \ref{cha:alg} presents the bacteriological algorithm.
    \item Chapter \ref{cha:sample} presents the method to generate sampling
    data.
	\item In chapter \ref{cha:proposal} we presents our framework with all components.
    \item In chapter \ref{cha:experiments} we discussed a case study performed with our solution.
	\item In chapter \ref{cha:conclusion} we conclude our results.
\end{itemize}

%The next section introduces the  fundamental concepts of the MapReduce framework and briefly describes different testing scenarios for MapReduce applications. Chapter~\ref{cha:proposal} introduces two test quality assessment methods, describes methods to data test generation and meta-heuristic search methods. Two data test generators are presented with their results.
%Chapter~\ref{cha:related} discusses related work. 
%Chapter~\ref{cha:conclusion} concludes.

% chapter introduction (end)
